{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNG562-Assignment1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisanuro/CNG562-Assignment-1/blob/master/CNG562_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7xb3nOt1MJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt  \n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn import metrics, datasets, preprocessing\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNATKa--c7Z0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kFold(foldNumber, X_train, Y_train):\n",
        "  #creating cross validation method with according to foldNumber\n",
        "  kf = KFold(n_splits=foldNumber, shuffle=False)\n",
        "  \n",
        "  #creating both linear & logistic regression models\n",
        "  logReg = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
        "  linReg = LinearRegression()\n",
        "  \n",
        "  #getting cross validation score according to logistic & linear\n",
        "  cv_result_log = cross_val_score(logReg, X_train, Y_train, cv=kf, scoring='accuracy')\n",
        "  cv_result_lin = cross_val_score(linReg, X_train, Y_train, cv=kf, scoring='neg_mean_squared_error')\n",
        "\n",
        "  #displaying results\n",
        "  print(str(foldNumber) + \"Fold\")\n",
        "  print(\"Logistic Regression Accuracy: \", cv_result_log.mean())\n",
        "  print(\"Linear Regression Accuracy: \", 1 + cv_result_lin.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D9wHIq3ceJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def randomOneHoldout(X_train, Y_train):\n",
        "  #splitting dataset as %80 train %20 test\n",
        "  x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=1)\n",
        "  \n",
        "  #creating both linear & logistic regression models\n",
        "  logReg = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
        "  linReg = LinearRegression()\n",
        "\n",
        "  #training the models\n",
        "  logReg.fit(x_train, y_train)\n",
        "  linReg.fit(x_train, y_train)\n",
        "\n",
        "  #predicting values \n",
        "  y_pred_log = logReg.predict(x_test)\n",
        "  y_pred_lin = linReg.predict(x_test)\n",
        "  \n",
        "  #displaying results\n",
        "  print(\"Random One Hold Out\")\n",
        "  print(\"Logistic Regression Accuracy: \", 1 - metrics.mean_squared_error(y_test, y_pred_log))\n",
        "  print(\"Linear Regression Accuracy: \", 1 - metrics.mean_squared_error(y_test, y_pred_lin))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evz_cnDudAiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stratifiedOneHoldout(X_train, Y_train):\n",
        "  #splitting dataset as %80 train %20 test\n",
        "  x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=1, stratify=Y_train)\n",
        "  \n",
        "  #creating both linear & logistic regression models\n",
        "  logReg = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
        "  linReg = LinearRegression()\n",
        "\n",
        "  #training the models\n",
        "  logReg.fit(x_train, y_train)\n",
        "  linReg.fit(x_train, y_train)\n",
        "\n",
        "  #predicting values \n",
        "  y_pred_log = logReg.predict(x_test)\n",
        "  y_pred_lin = linReg.predict(x_test)\n",
        "  \n",
        "  #displaying results\n",
        "  print(\"Stratified\")\n",
        "  print(\"Logistic Regression Accuracy: \", 1 - metrics.mean_squared_error(y_test, y_pred_log))\n",
        "  print(\"Linear Regression Accuracy: \", 1 - metrics.mean_squared_error(y_test, y_pred_lin))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5LKjla4N3Al",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def displayAccuracy(X, Y):\n",
        "    #splitting dataset as %80 train %20 test\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        "    \n",
        "    #running kFold accuracy method as 5Fold\n",
        "    kFold(5, X_train, Y_train)\n",
        "    #running kFold accuracy method as 10Fold\n",
        "    kFold(10, X_train, Y_train)\n",
        "    #running random one holdout method\n",
        "    randomOneHoldout(X_train, Y_train)\n",
        "    #running strafied one holdout method\n",
        "    stratifiedOneHoldout(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTg4V0rYWUoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#iris_data.mean(axis=0)\n",
        "#iris_data.std(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeUjkVzuWfnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stand_iris_data = preprocessing.scale(iris_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-poO-K3WhCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stand_iris_data.mean(axis=0)\n",
        "#stand_iris_data.std(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFXiNyrDsAQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs4klAsSguXu",
        "colab_type": "code",
        "outputId": "084c7b28-d517-4bcf-d494-9d0f136624f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  #loading raw iris dataset\n",
        "  iris = datasets.load_iris()\n",
        "  #loading raw iris data from dataset\n",
        "  X = iris.data\n",
        "  #loading iris titles from dataset \n",
        "  Y = iris.target\n",
        "  \n",
        "  #normalize raw data using L1 normalization technique\n",
        "  l1_norm = preprocessing.normalize(X, norm=\"l1\")\n",
        "  #normalize raw data using mean removal technique\n",
        "  mean_removal = preprocessing.scale(X)\n",
        "  \n",
        "  #mean & standart deviation before mean removal \n",
        "  print(X.mean(axis=0))\n",
        "  print(X.std(axis=0))\n",
        "\n",
        "  #mean & standart deviation after mean removal \n",
        "  print(mean_removal.mean(axis=0))\n",
        "  print(mean_removal.std(axis=0))\n",
        "\n",
        "  #Displaying result according to each type of methods and regression model\n",
        "  print(\"\\nRaw: \")\n",
        "  displayAccuracy(X,Y)\n",
        "  print(\"\\nL1 Normalization: \")\n",
        "  displayAccuracy(l1_norm,Y)\n",
        "  print(\"\\nMean Removal: \")\n",
        "  displayAccuracy(mean_removal,Y)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5.84333333 3.05733333 3.758      1.19933333]\n",
            "[0.82530129 0.43441097 1.75940407 0.75969263]\n",
            "[-1.69031455e-15 -1.84297022e-15 -1.69864123e-15 -1.40924309e-15]\n",
            "[1. 1. 1. 1.]\n",
            "\n",
            "Raw: \n",
            "5Fold\n",
            "Logistic Regression Accuracy:  0.9416666666666668\n",
            "Linear Regression Accuracy:  0.9505573483173648\n",
            "10Fold\n",
            "Logistic Regression Accuracy:  0.9333333333333332\n",
            "Linear Regression Accuracy:  0.9504757453551504\n",
            "Random One Hold Out\n",
            "Logistic Regression Accuracy:  0.9583333333333334\n",
            "Linear Regression Accuracy:  0.9596940114241354\n",
            "Stratified\n",
            "Logistic Regression Accuracy:  0.9583333333333334\n",
            "Linear Regression Accuracy:  0.9613449341091412\n",
            "\n",
            "L1 Normalization: \n",
            "5Fold\n",
            "Logistic Regression Accuracy:  0.6916666666666667\n",
            "Linear Regression Accuracy:  0.9249382972717285\n",
            "10Fold\n",
            "Logistic Regression Accuracy:  0.6916666666666667\n",
            "Linear Regression Accuracy:  0.9228036562601725\n",
            "Random One Hold Out\n",
            "Logistic Regression Accuracy:  0.75\n",
            "Linear Regression Accuracy:  0.9311930338541666\n",
            "Stratified\n",
            "Logistic Regression Accuracy:  0.7083333333333333\n",
            "Linear Regression Accuracy:  0.9382756551106771\n",
            "\n",
            "Mean Removal: \n",
            "5Fold\n",
            "Logistic Regression Accuracy:  0.8916666666666668\n",
            "Linear Regression Accuracy:  0.9505573483173648\n",
            "10Fold\n",
            "Logistic Regression Accuracy:  0.8833333333333334\n",
            "Linear Regression Accuracy:  0.9504757453551504\n",
            "Random One Hold Out\n",
            "Logistic Regression Accuracy:  1.0\n",
            "Linear Regression Accuracy:  0.9596940114241352\n",
            "Stratified\n",
            "Logistic Regression Accuracy:  0.9166666666666666\n",
            "Linear Regression Accuracy:  0.9613449341091413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6tMJf3yRw5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        " \n",
        "  linReg = LinearRegression()\n",
        "  logReg = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
        "  \n",
        "  linReg.fit(X_train, Y_train)\n",
        "  logReg.fit(X_train, Y_train)\n",
        "  #[[6, 3, 5, 1.5]]\n",
        "  Y_pred_lin = linReg.predict([[5.8, 4. , 1.2, 0.2]])\n",
        "  Y_pred_log = logReg.predict([[5.8, 4. , 1.2, 0.2]])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMmI3NRJWfg5",
        "colab_type": "code",
        "outputId": "24415459-cc1a-4bd6-85aa-856a2d9582b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#1 -metrics.mean_squared_error(Y_test, Y_pred_lin)\n",
        "Y_pred_lin"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.30170769])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzbYBde9nWVD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bfd8d179-efc1-402d-f3ef-fb55832c6b97"
      },
      "source": [
        "Y_pred_log"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Em11tVCvzAd",
        "colab_type": "text"
      },
      "source": [
        "# Finding Threshold using ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61U-P59TWpq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}