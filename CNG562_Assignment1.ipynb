{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNG562-Assignment1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisanuro/CNG562-Assignment-1/blob/master/CNG562_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEX_vKmhbU97",
        "colab_type": "text"
      },
      "source": [
        "# **CNG 562 - Assignment #1**\n",
        "\n",
        "Linear Regression vs Logistic Regression using Iris Dataset\\\n",
        "Comparing:\n",
        "*   Random 1-Hold Out\n",
        "*   5-Fold\n",
        "*   10-Fold\n",
        "*   Strafied 1-Hold Out\n",
        "\n",
        "\\\n",
        "Nisa Nur Odabaş\\\n",
        "Kaan Taha Köken\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7xb3nOt1MJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt  \n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn import metrics, datasets, preprocessing\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSeSvKNyd4WU",
        "colab_type": "text"
      },
      "source": [
        "**K-Fold method**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNATKa--c7Z0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kFold(foldNumber, X_train, Y_train):\n",
        "\n",
        "  kf = KFold(n_splits=foldNumber, shuffle=False)  \n",
        "\n",
        "  logReg = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
        "  linReg = LinearRegression()  \n",
        "\n",
        "  cv_result_log = cross_val_score(logReg, X_train, Y_train, cv=kf, scoring='accuracy')\n",
        "  cv_result_lin = cross_val_score(linReg, X_train, Y_train, cv=kf, scoring='neg_mean_squared_error')\n",
        "\n",
        "  print(str(foldNumber) + \"Fold\")\n",
        "  print(\"Logistic Regression Accuracy: \", cv_result_log.mean())\n",
        "  print(\"Linear Regression Accuracy: \", 1 + cv_result_lin.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyf75fcUeBB5",
        "colab_type": "text"
      },
      "source": [
        "**Random 1-Hold Out method**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D9wHIq3ceJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def randomOneHoldout(X_train, Y_train):\n",
        "\n",
        "  x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)\n",
        "  \n",
        "  logReg = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
        "  linReg = LinearRegression()\n",
        "\n",
        "  logReg.fit(x_train, y_train)\n",
        "  linReg.fit(x_train, y_train)\n",
        "\n",
        "  y_pred_log = logReg.predict(x_test)\n",
        "  y_pred_lin = linReg.predict(x_test)\n",
        "  \n",
        "  print(\"Random One Hold Out\")\n",
        "  print(\"Logistic Regression Accuracy: \", 1 - metrics.mean_squared_error(y_test, y_pred_log))\n",
        "  print(\"Linear Regression Accuracy: \", 1 - metrics.mean_squared_error(y_test, y_pred_lin))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPWS39aXeI6n",
        "colab_type": "text"
      },
      "source": [
        "**Stratified 1-Hold Out method**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evz_cnDudAiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stratifiedOneHoldout(X_train, Y_train):\n",
        "  \n",
        "  x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=0, stratify=Y_train)\n",
        "  \n",
        "  logReg = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
        "  linReg = LinearRegression()\n",
        "\n",
        "  logReg.fit(x_train, y_train)\n",
        "  linReg.fit(x_train, y_train)\n",
        "\n",
        "  y_pred_log = logReg.predict(x_test)\n",
        "  y_pred_lin = linReg.predict(x_test)\n",
        "  \n",
        "  print(\"Stratified\")\n",
        "  print(\"Logistic Regression Accuracy: \", 1 - metrics.mean_squared_error(y_test, y_pred_log))\n",
        "  print(\"Linear Regression Accuracy: \", 1 - metrics.mean_squared_error(y_test, y_pred_lin))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_2B_gqEeOd9",
        "colab_type": "text"
      },
      "source": [
        "**Displaying accuracies for all validation methods**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5LKjla4N3Al",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def displayAccuracy(X, Y):\n",
        "    \n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "    \n",
        "    kFold(5, X_train, Y_train)    \n",
        "    kFold(10, X_train, Y_train)    \n",
        "    randomOneHoldout(X_train, Y_train)\n",
        "    stratifiedOneHoldout(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fXFXbbvecNi",
        "colab_type": "text"
      },
      "source": [
        "**Round method for linear regression prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxbKsVBDL_ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def roundPredict(p):\n",
        "    r = p.copy()\n",
        "    for i in range(len(r)):\n",
        "        if r[i] <= 0.5: r[i] = 0\n",
        "        elif r[i] >= 1.5: r[i] = 2\n",
        "        else: r[i] = 1\n",
        "    return r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-5fN1oyejo-",
        "colab_type": "text"
      },
      "source": [
        "**Main**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs4klAsSguXu",
        "colab_type": "code",
        "outputId": "b0044950-7aca-40e8-b44f-417057989d2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "  iris = datasets.load_iris()\n",
        "  \n",
        "  X = iris.data\n",
        "  Y = iris.target\n",
        "  \n",
        "  # L1 normalization\n",
        "  l1_norm = preprocessing.normalize(X, norm=\"l1\")\n",
        "  # Mean removal\n",
        "  mean_removal = preprocessing.scale(X)\n",
        "\n",
        "  '''#mean & standart deviation before mean removal \n",
        "  print(X.mean(axis=0))\n",
        "  print(X.std(axis=0))\n",
        "\n",
        "  #mean & standart deviation after mean removal \n",
        "  print(mean_removal.mean(axis=0))\n",
        "  print(mean_removal.std(axis=0))'''\n",
        "\n",
        "  #Displaying result according to each type of methods and regression model\n",
        "  print(\"\\nRaw: \")\n",
        "  displayAccuracy(X,Y)\n",
        "  print(\"\\nL1 Normalization: \")\n",
        "  displayAccuracy(l1_norm,Y)\n",
        "  print(\"\\nMean Removal: \")\n",
        "  displayAccuracy(mean_removal,Y)"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Raw: \n",
            "5Fold\n",
            "Logistic Regression Accuracy:  0.9333333333333333\n",
            "Linear Regression Accuracy:  0.9497273362310497\n",
            "10Fold\n",
            "Logistic Regression Accuracy:  0.9333333333333332\n",
            "Linear Regression Accuracy:  0.9502722839017427\n",
            "Random One Hold Out\n",
            "Logistic Regression Accuracy:  0.8333333333333334\n",
            "Linear Regression Accuracy:  0.9183764782741906\n",
            "Stratified\n",
            "Logistic Regression Accuracy:  0.9583333333333334\n",
            "Linear Regression Accuracy:  0.9531984944502794\n",
            "\n",
            "L1 Normalization: \n",
            "5Fold\n",
            "Logistic Regression Accuracy:  0.6916666666666667\n",
            "Linear Regression Accuracy:  0.9185691833496094\n",
            "10Fold\n",
            "Logistic Regression Accuracy:  0.6916666666666667\n",
            "Linear Regression Accuracy:  0.9181168874104818\n",
            "Random One Hold Out\n",
            "Logistic Regression Accuracy:  0.7083333333333333\n",
            "Linear Regression Accuracy:  0.8837890625\n",
            "Stratified\n",
            "Logistic Regression Accuracy:  0.7083333333333333\n",
            "Linear Regression Accuracy:  0.9245198567708334\n",
            "\n",
            "Mean Removal: \n",
            "5Fold\n",
            "Logistic Regression Accuracy:  0.875\n",
            "Linear Regression Accuracy:  0.9497273362310498\n",
            "10Fold\n",
            "Logistic Regression Accuracy:  0.8833333333333334\n",
            "Linear Regression Accuracy:  0.9502722839017428\n",
            "Random One Hold Out\n",
            "Logistic Regression Accuracy:  0.7916666666666666\n",
            "Linear Regression Accuracy:  0.9183764782741907\n",
            "Stratified\n",
            "Logistic Regression Accuracy:  0.9166666666666666\n",
            "Linear Regression Accuracy:  0.9531984944502794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwS89vg5fEhF",
        "colab_type": "text"
      },
      "source": [
        "# **Final**\n",
        "**Training and Testing using:**\n",
        "* **Raw data**\n",
        "* **Stratified 1-Hold Out**\n",
        "* **Linear Regression**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H8jMNi4g1FU",
        "colab_type": "text"
      },
      "source": [
        "**Dividing Train and Test sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCRTm6pZg8nN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0, stratify=Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhNi5KMOxgcw",
        "colab_type": "text"
      },
      "source": [
        "Splitting dataset into 4.\n",
        "*   Train - 56%\n",
        "*   Train Dev - 14%\n",
        "*   Dev - 15%\n",
        "*   Test - 15%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oow4dOrkUk0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " Train_x, TrainDev_x, Train_y, TrainDev_y = train_test_split(X_train, Y_train, test_size=0.2, random_state=0, stratify=Y_train)\n",
        " Dev_x, Test_x, Dev_y, Test_y = train_test_split(X_test, Y_test, test_size=0.5, random_state=0, stratify=Y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xgm3mSbMhJy2",
        "colab_type": "text"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQEgrf5tuuOQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f28063d-6104-4419-bde7-4f3cf5637ad7"
      },
      "source": [
        "  linReg = LinearRegression()\n",
        "  linReg.fit(Train_x, Train_y)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBrwECDVhi94",
        "colab_type": "text"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP1bK9dKPfHT",
        "colab_type": "code",
        "outputId": "01141c3e-c309-42d0-e693-478251da926e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "  trainDev_pred = linReg.predict(TrainDev_x)\n",
        "  round_trainDev_pred = roundPredict(trainDev_pred)\n",
        "  \n",
        "  print(\"Train-Train Dev,   e1:\", metrics.mean_squared_error(TrainDev_y, trainDev_pred),\"\\n\")\n",
        "  print(\"Rounded Stratify One Hold Out - TrainDev\")\n",
        "  print(\"Linear Regression Accuracy: \", 1 - metrics.mean_squared_error(TrainDev_y, trainDev_pred))\n",
        "  print(\"Linear Regression R^2 score: \", metrics.r2_score(TrainDev_y, trainDev_pred))\n",
        "\n",
        "  print(\"\\ntrainDev_pred   \\tTrainDev_y\\trounded\")\n",
        "  for i, (j, k) in sorted(zip(trainDev_pred, zip(TrainDev_y, round_trainDev_pred))):\n",
        "    print(i , \"\\t\" , j, \"\\t\\t\", k)"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train-Train Dev,   e1: 0.05876313845669336 \n",
            "\n",
            "Rounded Stratify One Hold Out - TrainDev\n",
            "Linear Regression Accuracy:  0.9412368615433067\n",
            "Linear Regression R^2 score:  0.91185529231496\n",
            "\n",
            "trainDev_pred   \tTrainDev_y\trounded\n",
            "-0.13839147720498163 \t 0 \t\t 0.0\n",
            "-0.020046458285302993 \t 0 \t\t 0.0\n",
            "-0.010544867798288726 \t 0 \t\t 0.0\n",
            "-0.00257374725955245 \t 0 \t\t 0.0\n",
            "0.00430619661238496 \t 0 \t\t 0.0\n",
            "0.04743188973070861 \t 0 \t\t 0.0\n",
            "0.09601163203673474 \t 0 \t\t 0.0\n",
            "0.8529057223353345 \t 1 \t\t 1.0\n",
            "1.0582147675441174 \t 1 \t\t 1.0\n",
            "1.2731067662698674 \t 1 \t\t 1.0\n",
            "1.3141104768592393 \t 1 \t\t 1.0\n",
            "1.331988762171668 \t 1 \t\t 1.0\n",
            "1.3843000999760933 \t 1 \t\t 1.0\n",
            "1.4333817263770279 \t 1 \t\t 1.0\n",
            "1.4784285382481448 \t 2 \t\t 1.0\n",
            "1.555788618794975 \t 2 \t\t 2.0\n",
            "1.7322149705076941 \t 2 \t\t 2.0\n",
            "1.9601519969160788 \t 2 \t\t 2.0\n",
            "1.9751912196295316 \t 2 \t\t 2.0\n",
            "2.0277847842400685 \t 2 \t\t 2.0\n",
            "2.1217438364258645 \t 2 \t\t 2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZFlCzQV24Wf",
        "colab_type": "text"
      },
      "source": [
        "Add TrainDev to Train and create new model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N2XM6Z323Kl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  #linReg = LinearRegression()\n",
        "  #linReg.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6tMJf3yRw5L",
        "colab_type": "code",
        "outputId": "1276e934-7c13-40ce-f4d7-8639c7e287c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "dev_pred = linReg.predict(Dev_x)\n",
        "round_dev_pred = roundPredict(dev_pred)\n",
        "\n",
        "print(\"Train-Dev,   e2\", metrics.mean_squared_error(Dev_y, dev_pred),\"\\n\")\n",
        "print(\"Rounded Stratify One Hold Out - Dev\")\n",
        "print(\"Linear Regression Accuracy: \", 1 - metrics.mean_squared_error(Dev_y, dev_pred))\n",
        "print(\"Linear Regression R^2 score: \", metrics.r2_score(Dev_y, dev_pred))\n",
        "\n",
        "print(\"\\ndev_pred     \\t      Dev_y\\trounded\")\n",
        "for i, (j, k) in sorted(zip(dev_pred, zip(Dev_y, round_dev_pred))):\n",
        "    print(i , \"\\t\" , j, \"\\t\", k)"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train-Dev,   e2 0.050911109070897693 \n",
            "\n",
            "Rounded Stratify One Hold Out - Dev\n",
            "Linear Regression Accuracy:  0.9490888909291023\n",
            "Linear Regression R^2 score:  0.9251034140112022\n",
            "\n",
            "dev_pred     \t      Dev_y\trounded\n",
            "-0.058514325307117476 \t 0 \t 0.0\n",
            "-0.010649443062331787 \t 0 \t 0.0\n",
            "-0.007315156394797795 \t 0 \t 0.0\n",
            "0.008037792110784314 \t 0 \t 0.0\n",
            "0.06479780548363284 \t 0 \t 0.0\n",
            "0.1205292330031118 \t 0 \t 0.0\n",
            "0.1973000209780516 \t 0 \t 0.0\n",
            "0.9650856574443161 \t 1 \t 1.0\n",
            "1.1234455655418274 \t 1 \t 1.0\n",
            "1.1431426143517895 \t 1 \t 1.0\n",
            "1.2081664818301967 \t 1 \t 1.0\n",
            "1.2807873732505648 \t 1 \t 1.0\n",
            "1.344209914511452 \t 1 \t 1.0\n",
            "1.3951230098832994 \t 1 \t 1.0\n",
            "1.603258412217679 \t 2 \t 2.0\n",
            "1.6060532703572574 \t 2 \t 2.0\n",
            "1.698465300387035 \t 2 \t 2.0\n",
            "1.7118218338530151 \t 2 \t 2.0\n",
            "1.7570672894915074 \t 2 \t 2.0\n",
            "1.8425030658411172 \t 2 \t 2.0\n",
            "2.1644512284880157 \t 2 \t 2.0\n",
            "2.1660630614662466 \t 2 \t 2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUhWtFNvBupT",
        "colab_type": "code",
        "outputId": "64ce9251-9dd4-44dc-87fe-3516251dd71b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "test_pred = linReg.predict(Test_x)\n",
        "round_test_pred= roundPredict(test_pred)\n",
        "\n",
        "\n",
        "print(\"Train-Test,   e3: \", metrics.mean_squared_error(Test_y, test_pred),\"\\n\")\n",
        "print(\"Rounded Stratify One Hold Out - Test set\")\n",
        "print(\"Linear Regression Accuracy: \", 1 - metrics.mean_squared_error(Test_y, test_pred))\n",
        "print(\"Linear Regression R^2 score: \", metrics.r2_score(Test_y, test_pred))\n",
        "\n",
        "print(\"\\ntest_pred     \\t      Test_y\\trounded\")\n",
        "for i, (j, k) in sorted(zip(test_pred, zip(Test_y, round_test_pred))):\n",
        "  print(i , \"\\t\" , j, \"\\t\", k)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train-Test,   e3:  0.05383934801884544 \n",
            "\n",
            "Rounded Stratify One Hold Out - Test set\n",
            "Linear Regression Accuracy:  0.9461606519811545\n",
            "Linear Regression R^2 score:  0.9172063514477639\n",
            "\n",
            "test_pred     \t      Test_y\trounded\n",
            "-0.13285162496975972 \t 0 \t 0.0\n",
            "-0.07820915410829629 \t 0 \t 0.0\n",
            "-0.07032161660829617 \t 0 \t 0.0\n",
            "-0.07013345830551695 \t 0 \t 0.0\n",
            "-0.05387971144469844 \t 0 \t 0.0\n",
            "-0.03619784989086178 \t 0 \t 0.0\n",
            "-0.032965918478587486 \t 0 \t 0.0\n",
            "0.028721442323502322 \t 0 \t 0.0\n",
            "0.9246026031663763 \t 1 \t 1.0\n",
            "1.1454505351747373 \t 1 \t 1.0\n",
            "1.1525396295747607 \t 1 \t 1.0\n",
            "1.2379754059243706 \t 1 \t 1.0\n",
            "1.2686790829267514 \t 1 \t 1.0\n",
            "1.304422948078229 \t 1 \t 1.0\n",
            "1.3495638284526783 \t 1 \t 1.0\n",
            "1.3589608436756495 \t 1 \t 1.0\n",
            "1.472836194801598 \t 2 \t 1.0\n",
            "1.6034443505116747 \t 2 \t 2.0\n",
            "1.6930300234158557 \t 2 \t 2.0\n",
            "1.7171735277854578 \t 2 \t 2.0\n",
            "1.7520143745729162 \t 2 \t 2.0\n",
            "1.935299677932266 \t 2 \t 2.0\n",
            "2.028926232109409 \t 2 \t 2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43p8lSuCPCJb",
        "colab_type": "code",
        "outputId": "b1d8b3bd-60aa-4e6c-9881-198a8d9996d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "devTest_pred = linReg.predict(X_test)\n",
        "rounded_lin = roundPredict(devTest_pred)\n",
        "\n",
        "\n",
        "print(\"Train-(Dev+Test),   e4: \", metrics.mean_squared_error(Y_test, devTest_pred),\"\\n\")\n",
        "print(\"Rounded Stratify One Hold Out - Test set\")\n",
        "print(\"Linear Regression Accuracy: \", 1 - metrics.mean_squared_error(Y_test, devTest_pred))\n",
        "print(\"Linear Regression R^2 score: \", metrics.r2_score(Y_test, devTest_pred))\n",
        "\n",
        "print(\"\\ndevTest_pred  \\t\\t Dev+Test \\trounded\")\n",
        "for i, (j, k) in sorted(zip(devTest_pred, zip(Y_test, rounded_lin))):\n",
        "  print(i , \"\\t\" , j, \"\\t\\t\", k)"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train-(Dev+Test),   e4:  0.05240776453318211 \n",
            "\n",
            "Rounded Stratify One Hold Out - Test set\n",
            "Linear Regression Accuracy:  0.9475922354668179\n",
            "Linear Regression R^2 score:  0.9213883532002268\n",
            "\n",
            "devTest_pred  \t\t Dev+Test \trounded\n",
            "-0.13285162496975972 \t 0 \t\t 0.0\n",
            "-0.07820915410829629 \t 0 \t\t 0.0\n",
            "-0.07032161660829617 \t 0 \t\t 0.0\n",
            "-0.07013345830551695 \t 0 \t\t 0.0\n",
            "-0.058514325307117476 \t 0 \t\t 0.0\n",
            "-0.05387971144469844 \t 0 \t\t 0.0\n",
            "-0.03619784989086178 \t 0 \t\t 0.0\n",
            "-0.032965918478587486 \t 0 \t\t 0.0\n",
            "-0.010649443062331787 \t 0 \t\t 0.0\n",
            "-0.007315156394797795 \t 0 \t\t 0.0\n",
            "0.008037792110784314 \t 0 \t\t 0.0\n",
            "0.028721442323502322 \t 0 \t\t 0.0\n",
            "0.06479780548363284 \t 0 \t\t 0.0\n",
            "0.1205292330031118 \t 0 \t\t 0.0\n",
            "0.1973000209780516 \t 0 \t\t 0.0\n",
            "0.9246026031663763 \t 1 \t\t 1.0\n",
            "0.9650856574443161 \t 1 \t\t 1.0\n",
            "1.1234455655418274 \t 1 \t\t 1.0\n",
            "1.1431426143517895 \t 1 \t\t 1.0\n",
            "1.1454505351747373 \t 1 \t\t 1.0\n",
            "1.1525396295747607 \t 1 \t\t 1.0\n",
            "1.2081664818301967 \t 1 \t\t 1.0\n",
            "1.2379754059243706 \t 1 \t\t 1.0\n",
            "1.2686790829267514 \t 1 \t\t 1.0\n",
            "1.2807873732505648 \t 1 \t\t 1.0\n",
            "1.304422948078229 \t 1 \t\t 1.0\n",
            "1.344209914511452 \t 1 \t\t 1.0\n",
            "1.3495638284526783 \t 1 \t\t 1.0\n",
            "1.3589608436756495 \t 1 \t\t 1.0\n",
            "1.3951230098832994 \t 1 \t\t 1.0\n",
            "1.472836194801598 \t 2 \t\t 1.0\n",
            "1.603258412217679 \t 2 \t\t 2.0\n",
            "1.6034443505116747 \t 2 \t\t 2.0\n",
            "1.6060532703572574 \t 2 \t\t 2.0\n",
            "1.6930300234158557 \t 2 \t\t 2.0\n",
            "1.698465300387035 \t 2 \t\t 2.0\n",
            "1.7118218338530151 \t 2 \t\t 2.0\n",
            "1.7171735277854578 \t 2 \t\t 2.0\n",
            "1.7520143745729162 \t 2 \t\t 2.0\n",
            "1.7570672894915074 \t 2 \t\t 2.0\n",
            "1.8425030658411172 \t 2 \t\t 2.0\n",
            "1.935299677932266 \t 2 \t\t 2.0\n",
            "2.028926232109409 \t 2 \t\t 2.0\n",
            "2.1644512284880157 \t 2 \t\t 2.0\n",
            "2.1660630614662466 \t 2 \t\t 2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjUToaP_i4wD",
        "colab_type": "text"
      },
      "source": [
        "**Predicting [6, 3, 5, 1.5]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czCbG4-KR6ZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred = linReg.predict([[6, 3, 5, 1.5]])\n",
        "rounded = roundPredict(Y_pred.copy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s_nKHMuSJqv",
        "colab_type": "code",
        "outputId": "26cda584-019d-4d58-faf9-ce74a22df50b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"Prediction: \\t\\t\",Y_pred)\n",
        "print(\"Predicted class: \\t\", rounded)\n",
        "print(\"Mean squared error: \\t\", metrics.mean_squared_error(rounded, Y_pred))\n",
        "print(\"Mean absolute error: \\t\", metrics.mean_absolute_error(rounded, Y_pred))"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: \t\t [1.39983899]\n",
            "Predicted class: \t [1.]\n",
            "Mean squared error: \t 0.15987121534579546\n",
            "Mean absolute error: \t 0.3998389867756713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Em11tVCvzAd",
        "colab_type": "text"
      },
      "source": [
        "**ROC**\\\n",
        "Using rounded predictions since linear regression has no ROC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4B7Xf47fd9C",
        "colab_type": "code",
        "outputId": "11848fd4-a2a0-4c89-d5fa-bb6f81c4206a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "scores=[]\n",
        "\n",
        "for i, j in sorted(zip(devTest_pred, Y_test)):\n",
        "    scores.append(float(j)- i)\n",
        "scores"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.13285162496975972,\n",
              " 0.07820915410829629,\n",
              " 0.07032161660829617,\n",
              " 0.07013345830551695,\n",
              " 0.058514325307117476,\n",
              " 0.05387971144469844,\n",
              " 0.03619784989086178,\n",
              " 0.032965918478587486,\n",
              " 0.010649443062331787,\n",
              " 0.007315156394797795,\n",
              " -0.008037792110784314,\n",
              " -0.028721442323502322,\n",
              " -0.06479780548363284,\n",
              " -0.1205292330031118,\n",
              " -0.1973000209780516,\n",
              " 0.07539739683362368,\n",
              " 0.03491434255568393,\n",
              " -0.1234455655418274,\n",
              " -0.14314261435178954,\n",
              " -0.14545053517473727,\n",
              " -0.15253962957476075,\n",
              " -0.2081664818301967,\n",
              " -0.2379754059243706,\n",
              " -0.26867908292675136,\n",
              " -0.2807873732505648,\n",
              " -0.304422948078229,\n",
              " -0.3442099145114521,\n",
              " -0.3495638284526783,\n",
              " -0.3589608436756495,\n",
              " -0.3951230098832994,\n",
              " 0.527163805198402,\n",
              " 0.39674158778232105,\n",
              " 0.39655564948832533,\n",
              " 0.3939467296427426,\n",
              " 0.30696997658414427,\n",
              " 0.3015346996129651,\n",
              " 0.2881781661469849,\n",
              " 0.28282647221454216,\n",
              " 0.2479856254270838,\n",
              " 0.24293271050849263,\n",
              " 0.15749693415888277,\n",
              " 0.06470032206773402,\n",
              " -0.02892623210940881,\n",
              " -0.16445122848801574,\n",
              " -0.1660630614662466]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61U-P59TWpq2",
        "colab_type": "code",
        "outputId": "27f81f4c-27ce-48b2-f3be-0637638f2d85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "#Prediction of the model\n",
        "temp = Y_test.copy()\n",
        "for i in range(len(Y_test)):\n",
        "    if Y_test[i] != 0: temp[i] = -1\n",
        "    else: temp[i] = 1\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(temp, scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(fpr)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.         0.03333333 0.03333333 0.16666667 0.16666667 0.2\n",
            " 0.2        0.3        0.3        0.36666667 0.36666667 0.46666667\n",
            " 0.46666667 0.5        0.5        0.53333333 0.53333333 0.63333333\n",
            " 0.63333333 0.66666667 0.66666667 0.76666667 0.76666667 1.        ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYYwxxq//A1fZKxKnX26LAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv3gtMxbeBoJ",
        "colab_type": "code",
        "outputId": "a1950af7-6bf0-4ad7-b280-fcfa033d9cf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "# Import some data to play with\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Binarize the output\n",
        "y = label_binarize(y, classes=[0, 1, 2])\n",
        "n_classes = y.shape[1]\n",
        "\n",
        "# Add noisy features to make the problem harder\n",
        "random_state = np.random.RandomState(0)\n",
        "n_samples, n_features = X.shape\n",
        "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
        "\n",
        "# shuffle and split training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n",
        "                                                    random_state=0)\n",
        "\n",
        "# Learn to predict each class against the other\n",
        "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
        "                                 random_state=random_state))\n",
        "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
        "print(y_score, y_test)\n",
        "# Compute ROC curve and ROC area for each class\n",
        "#fpr = dict()\n",
        "#tpr = dict()\n",
        "#roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    print(y_score[:, i])\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "#fpr, tpr, _ = roc_curve(, y_score[:, i])\n",
        "#roc_auc = auc(fpr, tpr)\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "#fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
        "#roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.76301132 -0.36482547  0.12386354]\n",
            " [-0.20224493 -0.63144366 -0.16612302]\n",
            " [ 0.11801481 -0.80263073 -0.32055874]\n",
            " [-0.90780855 -0.12395478  0.02199789]\n",
            " [-0.01116192 -0.27913475 -0.71889214]\n",
            " [-0.6048727  -0.34730509 -0.05859016]\n",
            " [ 0.02283491 -0.24506467 -0.79111998]\n",
            " [-0.61076876  0.18264917 -0.57199363]\n",
            " [-0.37572754 -0.24059516 -0.38933694]\n",
            " [-0.47017411 -0.25745136 -0.27510839]\n",
            " [-0.42224234 -0.30270719 -0.27995197]\n",
            " [-0.3355867  -0.7030665   0.02530178]\n",
            " [-0.22723929 -0.64062258 -0.13456902]\n",
            " [-0.07856729 -0.46354017 -0.45918364]\n",
            " [-0.53383361 -0.2653183  -0.20023832]\n",
            " [ 0.12163662 -0.56706353 -0.56980985]\n",
            " [-0.71356947 -0.04226738 -0.24297128]\n",
            " [-0.55111511 -0.13784913 -0.31370595]\n",
            " [ 0.37991331 -0.99673302 -0.39090964]\n",
            " [-0.11107635 -0.91349462  0.03129167]\n",
            " [-0.70713712 -0.06436533 -0.21423788]\n",
            " [-0.02392675 -0.45906496 -0.51922684]\n",
            " [-0.25045747 -0.80086123  0.04121338]\n",
            " [ 0.12675547 -0.70985659 -0.41072849]\n",
            " [-0.68210402 -0.20735021 -0.12051204]\n",
            " [-0.08001795 -0.36698232 -0.57704892]\n",
            " [-0.03259341 -0.1159895  -0.86493066]\n",
            " [-0.04953425 -0.73611276 -0.21682409]\n",
            " [-0.12974835 -0.37676258 -0.49997476]\n",
            " [-0.19299299 -0.71078341 -0.11058011]\n",
            " [-0.3619768  -0.41408367 -0.22759345]\n",
            " [-0.22818639 -0.78971942  0.02046723]\n",
            " [-0.06196433 -0.47617037 -0.45379557]\n",
            " [-0.52455061 -0.46507392 -0.00375631]\n",
            " [-0.40026409 -0.71470221  0.10106561]\n",
            " [-0.35056585 -0.31125083 -0.34020065]\n",
            " [-0.05770139 -0.51388968 -0.41776502]\n",
            " [-1.11907501 -0.0074193   0.12967625]\n",
            " [ 0.19599366 -0.65773489 -0.54610377]\n",
            " [-0.04299172 -0.60049718 -0.35901924]\n",
            " [-0.48108269 -0.21918849 -0.30065047]\n",
            " [ 0.1741885  -1.0107504  -0.181261  ]\n",
            " [-0.41416456 -0.60044961  0.00856393]\n",
            " [-0.01053513 -0.7579771  -0.2292247 ]\n",
            " [ 0.01645355 -0.81552421 -0.2039252 ]\n",
            " [-0.11932181 -0.84787471 -0.05831557]\n",
            " [-0.70817199 -0.2863326  -0.01186087]\n",
            " [-0.77303401 -0.43228203  0.21326435]\n",
            " [-0.61489613 -0.15060119 -0.23302033]\n",
            " [-0.96334774 -0.62804881  0.58423201]\n",
            " [-0.31037723 -0.29572764 -0.39404258]\n",
            " [-0.31952657 -0.34638653 -0.32086131]\n",
            " [-0.35306417 -0.66917752  0.00767521]\n",
            " [ 0.12127427 -0.62483455 -0.50550427]\n",
            " [-0.6643231  -0.11456775 -0.21298739]\n",
            " [-0.55149778 -0.34855346 -0.10551977]\n",
            " [-0.55695146 -0.13384038 -0.30613086]\n",
            " [-0.41111447 -0.52487765 -0.07455313]\n",
            " [-0.49463336 -0.23331763 -0.27802284]\n",
            " [ 0.06910059 -0.85448531 -0.21662877]\n",
            " [-0.23036784 -0.48759987 -0.28317657]\n",
            " [ 0.30342285 -0.83392076 -0.47754831]\n",
            " [ 0.17642852 -0.81597935 -0.3755452 ]\n",
            " [-0.1906155  -0.70826295 -0.10238744]\n",
            " [-0.42910413 -0.39894364 -0.1693745 ]\n",
            " [-0.67759563  0.09194626 -0.3995789 ]\n",
            " [-0.32958811 -0.56572577 -0.12075396]\n",
            " [-0.97119543 -0.46484965  0.41477557]\n",
            " [ 0.02088168 -0.56912947 -0.44616888]\n",
            " [-0.08177305 -0.5611945  -0.35229343]\n",
            " [-0.41466962 -0.63705856  0.04838688]\n",
            " [-0.30436228 -0.08425378 -0.61864694]\n",
            " [ 0.18869727 -0.8879586  -0.29713077]\n",
            " [ 0.24966175 -0.80507517 -0.44324457]\n",
            " [-0.39980476 -0.29016769 -0.30413406]] [[0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 1 0]]\n",
            "[-0.76301132 -0.20224493  0.11801481 -0.90780855 -0.01116192 -0.6048727\n",
            "  0.02283491 -0.61076876 -0.37572754 -0.47017411 -0.42224234 -0.3355867\n",
            " -0.22723929 -0.07856729 -0.53383361  0.12163662 -0.71356947 -0.55111511\n",
            "  0.37991331 -0.11107635 -0.70713712 -0.02392675 -0.25045747  0.12675547\n",
            " -0.68210402 -0.08001795 -0.03259341 -0.04953425 -0.12974835 -0.19299299\n",
            " -0.3619768  -0.22818639 -0.06196433 -0.52455061 -0.40026409 -0.35056585\n",
            " -0.05770139 -1.11907501  0.19599366 -0.04299172 -0.48108269  0.1741885\n",
            " -0.41416456 -0.01053513  0.01645355 -0.11932181 -0.70817199 -0.77303401\n",
            " -0.61489613 -0.96334774 -0.31037723 -0.31952657 -0.35306417  0.12127427\n",
            " -0.6643231  -0.55149778 -0.55695146 -0.41111447 -0.49463336  0.06910059\n",
            " -0.23036784  0.30342285  0.17642852 -0.1906155  -0.42910413 -0.67759563\n",
            " -0.32958811 -0.97119543  0.02088168 -0.08177305 -0.41466962 -0.30436228\n",
            "  0.18869727  0.24966175 -0.39980476]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-205-7000e0e9ae57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ]
    }
  ]
}